{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import daily_file\n",
    "import ftp_noaa\n",
    "\n",
    "ftp = ftp_noaa.ftp_noaa('pub/data/ghcn/daily/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_func_country_code(row):\n",
    "        return row.name[:2]\n",
    "\n",
    "def data_prep_func_year_count(row):\n",
    "    return row['LastYear'] - row['FirstYear']\n",
    "\n",
    "def mm_to_inches(row):\n",
    "    return row['VALUE'] / 25.4\n",
    "\n",
    "def get_station_snow(st_id):\n",
    "    ftp = ftp_noaa.ftp_noaa('pub/data/ghcn/daily/all')\n",
    "    ftp.retrieve_file('{}.dly'.format(st_id))\n",
    "    file = daily_file.daily_file('{}.dly'.format(st_id))\n",
    "    epply_df = file.df\n",
    "    epply_df = epply_df[epply_df['ELEMENT']=='SNOW']\n",
    "    epply_df = epply_df[epply_df['VALUE']>0]\n",
    "    epply_df['Snow (inches)'] = epply_df.apply(mm_to_inches, axis=1)\n",
    "    epply_df.sort_values(by='Snow (inches)', ascending=False)\n",
    "    epply_df = epply_df.rename(columns={'ID':'StationID'})\n",
    "    # read the stations file into memory and convert to a DataFrame\n",
    "    # then perform various cleansing and data prep operations\n",
    "    stationsDF = pd.read_fwf('ghcnd-stations.txt', header=None, delimiter=' '\n",
    "                     , widths=[12,9,10,7,3,31,4,4,6]\n",
    "                     , names=['StationID', 'Latitude', 'Longitude', 'Elevation'\n",
    "                            ,'State', 'StationName', 'GSN_Flag', 'HCN_CRN_Flag'\n",
    "                            ,'WMO_ID']\n",
    "                     , dtypes={'WMO_ID':object},index_col='StationID'\n",
    "                     )\n",
    "    stationsDF['CountryCode']= stationsDF.apply(data_prep_func_country_code, axis=1)\n",
    "\n",
    "    # merge the stations DataFrame with states and countries master data\n",
    "    countriesDF = pd.read_fwf('ghcnd-countries.txt',header=None,delimiter=' '\n",
    "                            ,names=['CountryCode','CountryName'])\n",
    "    stationsDF = stationsDF.reset_index().merge(countriesDF,on='CountryCode',how='left').set_index('StationID')\n",
    "\n",
    "    statesDF = pd.read_fwf('ghcnd-states.txt',header=None,delimiter=' '\n",
    "                            ,names=['State','StateName'])\n",
    "    stationsDF= stationsDF.reset_index().merge(statesDF,on='State',how='left').set_index('StationID')\n",
    "    epply_df = pd.merge(epply_df, stationsDF, right_index=True, left_on='StationID')\n",
    "    epply_df.to_csv('{}_snow.csv'.format(st_id, sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_station_snow('US1NEWS0004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = ftp_noaa.ftp_noaa('pub/data/ghcn/daily/all')\n",
    "ftp.retrieve_file('USW00014942.dly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nate\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:741: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "file = daily_file.daily_file('USW00014942.dly')\n",
    "epply_df = file.df\n",
    "epply_df = epply_df[epply_df['ELEMENT']=='SNOW']\n",
    "epply_df = epply_df[epply_df['VALUE']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_to_inches(row):\n",
    "    return row['VALUE'] / 25.4\n",
    "\n",
    "epply_df['Snow (inches)'] = epply_df.apply(mm_to_inches, axis=1)\n",
    "epply_df.sort_values(by='Snow (inches)', ascending=False)\n",
    "epply_df = epply_df.rename(columns={'ID':'StationID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_func_country_code(row):\n",
    "        return row.name[:2]\n",
    "\n",
    "def data_prep_func_year_count(row):\n",
    "    return row['LastYear'] - row['FirstYear']\n",
    "\n",
    "# read the stations file into memory and convert to a DataFrame\n",
    "# then perform various cleansing and data prep operations\n",
    "stationsDF = pd.read_fwf('ghcnd-stations.txt', header=None, delimiter=' '\n",
    "                 , widths=[12,9,10,7,3,31,4,4,6]\n",
    "                 , names=['StationID', 'Latitude', 'Longitude', 'Elevation'\n",
    "                        ,'State', 'StationName', 'GSN_Flag', 'HCN_CRN_Flag'\n",
    "                        ,'WMO_ID']\n",
    "                 , dtypes={'WMO_ID':object},index_col='StationID'\n",
    "                 )\n",
    "stationsDF['CountryCode']= stationsDF.apply(data_prep_func_country_code, axis=1)\n",
    "\n",
    "# merge the stations DataFrame with states and countries master data\n",
    "countriesDF = pd.read_fwf('ghcnd-countries.txt',header=None,delimiter=' '\n",
    "                        ,names=['CountryCode','CountryName'])\n",
    "stationsDF = stationsDF.reset_index().merge(countriesDF,on='CountryCode',how='left').set_index('StationID')\n",
    "\n",
    "statesDF = pd.read_fwf('ghcnd-states.txt',header=None,delimiter=' '\n",
    "                        ,names=['State','StateName'])\n",
    "stationsDF= stationsDF.reset_index().merge(statesDF,on='State',how='left').set_index('StationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epply_df = pd.merge(epply_df, stationsDF, right_index=True, left_on='StationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(row):\n",
    "    if row['MONTH'] < 6:\n",
    "        return str(row['YEAR'] - 1)[2:4] + '-' + str(row['YEAR'])[2:4]\n",
    "    else:\n",
    "        return str(row['YEAR'])[2:4] + '-' + str(row['YEAR'] + 1)[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epply_df['Season'] = epply_df.apply(get_season, axis=1)\n",
    "epply_df.sort_values(by=['YEAR', 'MONTH'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epply_df.to_csv('epply_snow.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
